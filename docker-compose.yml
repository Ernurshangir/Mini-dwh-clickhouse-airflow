version: '3.8'

x-airflow-common: &airflow-common
  image: apache/airflow:2.9.3
  platform: linux/amd64 
  env_file: .env
  user: "${AIRFLOW_UID:-50000}:0"
  volumes:
    - ./airflow/dags:/opt/airflow/dags
    - ./airflow/logs:/opt/airflow/logs
    - ~/Desktop/mini_dwh/dbt:/opt/airflow/dbt
  environment:
    _PIP_ADDITIONAL_REQUIREMENTS: "dbt-core dbt-clickhouse clickhouse-connect pandas sqlalchemy psycopg2-binary python-dotenv"
    AIRFLOW__CORE__LOAD_EXAMPLES: "False"
  deploy:
    resources:
      limits:
        memory: 1G  # Ограничиваем Airflow, чтобы не съел все

services:
  # 1. PostgreSQL
  postgres:
    image: postgres:15
    container_name: pg_demo
    env_file: .env
    ports:
      - "${POSTGRES_PORT}:5432"
    volumes:
      - pg_data:/var/lib/postgresql/data
      - ./sql:/docker-entrypoint-initdb.d
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U demo"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 512M # Postgres очень экономный, ему хватит

  # 2. ClickHouse
  clickhouse:
    image: clickhouse/clickhouse-server:23.8
    container_name: ch_demo
    ulimits:
      nofile:
        soft: 262144
        hard: 262144
    ports:
      - "${CH_HTTP_PORT}:8123"
      - "${CH_NATIVE_PORT}:9000"
    volumes:
      - ch_data:/var/lib/clickhouse
    environment:
      CLICKHOUSE_USER: ${CH_USER}
      CLICKHOUSE_PASSWORD: ${CH_PASSWORD}
      CLICKHOUSE_DB: ${CH_DB}
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "localhost:8123/ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 1.5G # Даем ClickHouse дышать, но не более

  # 3. Airflow Init
  airflow-init:
    <<: *airflow-common
    container_name: airflow_init
    depends_on:
      postgres:
        condition: service_healthy
    command: >
      bash -c "airflow db migrate && 
      airflow users create --username ${AIRFLOW_USER} --password ${AIRFLOW_PASSWORD} --firstname Admin --lastname User --role Admin --email ${AIRFLOW_EMAIL} || true"

  # 4. Airflow Webserver
  airflow-web:
    <<: *airflow-common
    container_name: airflow_web
    ports:
      - "${AIRFLOW_PORT}:8080"
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    command: webserver

  # 5. Airflow Scheduler
  airflow-scheduler:
    <<: *airflow-common
    container_name: airflow_scheduler
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    command: scheduler

  # 6. Apache Superset (С ИСПРАВЛЕНИЯМИ)
  superset:
    image: apache/superset:latest
    container_name: superset_demo
    platform: linux/amd64
    env_file: .env
    ports:
      - "${SUPERSET_PORT}:8088"
    depends_on:
      clickhouse:
        condition: service_healthy
    user: "root"
    environment:
      - SUPERSET_SECRET_KEY=complex_random_secret_string_12345
      - SUPERSET_LOAD_EXAMPLES=no
      - GUNICORN_TIMEOUT=120 # Важно для M2: даем больше времени на раздумья
    deploy:
      resources:
        limits:
          memory: 2G # Superset самый прожорливый
    # ВОТ ГЛАВНОЕ ИСПРАВЛЕНИЕ НИЖЕ:
    entrypoint: >
      /bin/sh -c "
      echo 'Installing ClickHouse Drivers...' &&
      pip install clickhouse-connect clickhouse-sqlalchemy &&
      echo 'Drivers installed. Starting Superset...' &&
      superset db upgrade &&
      superset fab create-admin --username admin --firstname Admin --lastname Admin --email admin@example.com --password admin || true &&
      superset init &&
      /usr/bin/run-server.sh"

volumes:
  pg_data:
  ch_data: